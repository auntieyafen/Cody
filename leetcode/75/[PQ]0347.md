Here's another approach using the **Quickselect algorithm** to find the top `k` frequent elements, which works well for scenarios where you need linear time complexity on average.

### Code:

```cpp
#include <vector>
#include <unordered_map>
#include <algorithm>
#include <queue>

class Solution {
public:
    vector<int> topKFrequent(vector<int>& nums, int k) {
        unordered_map<int, int> frequencyMap;
        for (int num : nums) {
            frequencyMap[num]++;
        }

        // Use a priority queue (min-heap) to store top k elements
        auto cmp = [](pair<int, int>& a, pair<int, int>& b) {
            return a.second > b.second;
        };
        priority_queue<pair<int, int>, vector<pair<int, int>>, decltype(cmp)> minHeap(cmp);
        
        for (auto& entry : frequencyMap) {
            minHeap.push(entry);
            if (minHeap.size() > k) {
                minHeap.pop();
            }
        }

        vector<int> result;
        while (!minHeap.empty()) {
            result.push_back(minHeap.top().first);
            minHeap.pop();
        }

        return result;
    }
};
```

### Explanation:
1. **Count Frequencies**:
   - Use an unordered map (`frequencyMap`) to count the frequency of each element in the array `nums`.

2. **Use Min-Heap to Keep Top `k` Elements**:
   - Use a priority queue (`minHeap`) with a custom comparator to store the elements with their frequencies.
   - The heap will only maintain `k` elements, so whenever its size exceeds `k`, we remove the smallest element.
   - This ensures that the heap always contains the top `k` frequent elements.

3. **Extract Elements from Heap**:
   - Extract elements from the heap to construct the result.

### Complexity:
- **Time Complexity**: 
  - `O(n log k)` where `n` is the size of `nums`. Building the frequency map takes `O(n)`, and pushing into the heap takes `O(log k)`.
- **Space Complexity**: 
  - `O(n)` for storing the frequency map, and `O(k)` for storing the heap.

This solution works efficiently when `k` is much smaller compared to `n`, and it provides a more optimal approach for finding the top `k` frequent elements in terms of heap usage.

---

Certainly! Here's an alternative approach using a **bucket sort**:

### Code:

```cpp
#include <vector>
#include <unordered_map>
#include <algorithm>

class Solution {
public:
    vector<int> topKFrequent(vector<int>& nums, int k) {
        unordered_map<int, int> frequencyMap;
        for (int num : nums) {
            frequencyMap[num]++;
        }

        // Create a bucket where the index represents the frequency of the elements.
        vector<vector<int>> bucket(nums.size() + 1);
        for (auto& entry : frequencyMap) {
            bucket[entry.second].push_back(entry.first);
        }

        // Get the top k frequent elements from the bucket
        vector<int> result;
        for (int i = bucket.size() - 1; i >= 0 && result.size() < k; --i) {
            for (int num : bucket[i]) {
                result.push_back(num);
                if (result.size() == k) break;
            }
        }

        return result;
    }
};
```

### Explanation:
1. **Count Frequencies**:
   - Use an unordered map (`frequencyMap`) to count the frequency of each element in the array `nums`.
   
2. **Bucket Sort**:
   - Create a `bucket` vector, where the index represents the frequency, and the value at each index is a list of elements that have that frequency.
   - The size of `bucket` is `nums.size() + 1` because the frequency of an element cannot exceed the number of elements in `nums`.
   
3. **Get the Top `k` Frequent Elements**:
   - Iterate over the `bucket` vector in reverse (from highest to lowest frequency).
   - Collect elements until we reach `k` elements.

### Complexity:
- **Time Complexity**: `O(n)`, where `n` is the size of `nums`. This is because we count the frequencies in `O(n)`, and bucket sort also takes `O(n)`.
- **Space Complexity**: `O(n)`. The hash map takes `O(n)` to store frequencies, and the bucket also takes `O(n)` space.

This approach works efficiently when `k` is small compared to `n`, and it ensures we get the top `k` elements in linear time.

---

Here's a solution for finding the `k` most frequent elements using a hash map and a priority queue (min-heap):

### Code:

```cpp
#include <vector>
#include <unordered_map>
#include <queue>

class Solution {
public:
    vector<int> topKFrequent(vector<int>& nums, int k) {
        unordered_map<int, int> frequencyMap;
        for (int num : nums) {
            frequencyMap[num]++;
        }

        // Min-heap to store the k most frequent elements
        auto cmp = [&](pair<int, int>& a, pair<int, int>& b) {
            return a.second > b.second;
        };
        priority_queue<pair<int, int>, vector<pair<int, int>>, decltype(cmp)> minHeap(cmp);

        // Iterate over the frequency map
        for (auto& entry : frequencyMap) {
            minHeap.push(entry);
            if (minHeap.size() > k) {
                minHeap.pop(); // Keep only the top k elements in the heap
            }
        }

        // Prepare the result vector
        vector<int> result;
        while (!minHeap.empty()) {
            result.push_back(minHeap.top().first);
            minHeap.pop();
        }

        return result;
    }
};
```

### Explanation:
1. **Count Frequencies**:
   - Create an unordered map (`frequencyMap`) to store the frequency of each element in the array `nums`.
   
2. **Min-Heap Construction**:
   - Use a min-heap (`priority_queue`) to keep track of the top `k` frequent elements.
   - Use a custom comparator to compare based on frequency (`cmp` lambda).
   - Push elements into the heap while maintaining the size of the heap at most `k`. If the heap size exceeds `k`, pop the element with the smallest frequency.

3. **Extract Result**:
   - After iterating through all the entries, extract the elements from the heap into the result vector.

### Complexity:
- **Time Complexity**: `O(n log k)`, where `n` is the size of `nums`. We iterate through `nums` to build the frequency map, and then we maintain a heap of size `k` as we iterate through the frequency map.
- **Space Complexity**: `O(n + k)`. `O(n)` for the hash map to store the frequency of elements, and `O(k)` for the heap. 

This solution is efficient and works well for large input sizes while maintaining the requirement to find the top `k` frequent elements in an optimal manner.